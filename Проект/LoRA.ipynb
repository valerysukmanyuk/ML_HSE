{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c383b8e0",
   "metadata": {},
   "source": [
    "#### В этом ноутбуке я обучаю две версии модели \"Helsinki-NLP/opus-mt-ru-en\" на двух версиях датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fc26e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq, pipeline\n",
    "from datasets import Dataset\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3489be5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432,
     "referenced_widgets": [
      "6f29b3828e1b4486890d63ebdd5e6ffd",
      "8c2d588beed44470aa8a6d76cff3599c",
      "d49dcee4c55e49feb5e33a2b74fad1bf",
      "08f2269ff30045528c319c51ce0c4894",
      "555e27d3ee01471ca427a47a343a5727",
      "2e2ef38d12d94fa9ad72926318634ab1",
      "05a27bcfc9964f7fbea8846d34008514",
      "b366eb814c704bcd85df1eef4797fac7",
      "bbd005277ce04b81a9bda95bcf6a4e80",
      "4d083556a61349febc050051206d5741",
      "8b6dc6e6807446b3b8f0ff90828032e8",
      "94d78c532a644c7db9039af7175f6ee6",
      "fcb007c9d775428aa599d596a5ef241d",
      "d60d2f0f2d6b419b8ba61d56ecf4143a",
      "afcdadc0092e44ee84dda5a4e5b08659",
      "6c512df3518440f2b94a7c02fc311049",
      "84b45884a80a4b6ab92f04acec59e990",
      "b94dd00a066b41c29918d61ea8959a4a",
      "dae39f82a4d8462fbf73dafaf3d86bf6",
      "7125ad842f674ea997612b4235e05e83",
      "7cfe3dcd24f743beb8085077bd1bcf5f",
      "3123e9c9d4e34acd9d1348f0cb91a90c",
      "d37898e5d3614e1d855cd3d341e5e839",
      "063ab838ac1a48379037a0c09267bbc2",
      "4c5fe3d27c90445989658a039cd4d9e1",
      "c28c4ef14a124ac7a52d4d2e4750ba3f",
      "e5fcdf95e4c744168dc9e889eb53f003",
      "4bba55f81a824e11ae133de046a4e936",
      "3a7537423c9c4d5780d178750d41c10d",
      "e0bb9065d5d548c7948317862126cb14",
      "f4ff7c5fa6e345f38b2eb248ee689e9b",
      "8d6e39cd0a724733ba79a4584b213522",
      "c586bb9b43444e5b8e79fcc3c5d03a10",
      "deb3d651c02743649d1db10f1cc598c3",
      "752113aa2cfe427b8419ef1fa0c6fbfe",
      "c52ec7beece544b8bbf4f23d0ced5a39",
      "c27095045dc246bb836a0885b46de91b",
      "0f2185146e6a496aa86900e873612f4f",
      "e6df7e11662a41cc84e84c4bf4b464a0",
      "74222d4316fb41aa80b3de88dc20fb91",
      "ba01ef9d95cb47c2951b4b68ba31fe24",
      "213683b7dfd24884a11b166bbf778a8a",
      "cb1ecca0f57340c7b45b899fc425ff52",
      "43919097e3734c43b9fa1dbdfe67c03b",
      "2f4bf72d00a840d0827b362265488a7c",
      "a11acb1f57d849f5a94aadd5a10af3c9",
      "9085788812c947cfa2cfa5375b45f063",
      "26c4a363cc504a5387d19c7cb58421b2",
      "d04d6989770d4d8d90382c6fc67c12ac",
      "7d70ab15086e45cba5da23de6fe4144d",
      "566e8537cf24476d8e36d21d5f6aeede",
      "b9bbab7a1e7b451c888f19e3794fc81e",
      "5f50bbf788334625b9fd2944f9e14d7d",
      "e8a76c37b22f4ff1a378f842a8e0d59d",
      "5cc8fc949bbf4607a9721f595c128f59",
      "fedffb0e857e426b963390e949d7537e",
      "bfefd66fe1c340669b841ef0f7378df7",
      "8f43f6b6f5c14b87b0f66b40982586c0",
      "ad4374aceb754beb9672c5d93658cc5e",
      "45525d51087a4eabaf909c088819f212",
      "37eb456fd03546adac8339fd209c4e96",
      "f0c4835848ed4afeabad5deb40ec9fd6",
      "4895c77b6a5748bc80319060ea30f390",
      "d16757d898314d2a925cea7c1355146b",
      "bf500418bdcb49898f8ab08ebf48a173",
      "d6f4ab4431034850ac9d3787a7d97076",
      "6acd630f01b64587be1ec796d39a1073",
      "b2f8606b4af148f5a4735e01bc19bd43",
      "96472260702d4b859c3d77ca8c580d6c",
      "2a3a696d89f045c593987b19928fd200",
      "4693dbac5a2346f794dc20cd484163fe",
      "8d379e5a659e4d56a9e616b217676d5b",
      "ea6745faea8d44c08a4610c5b5ae0d73",
      "47d02a4edcff41279962b5db87f7fed9",
      "b9ae7273a68c47769929e8d8f0242319",
      "a2c33b66093649669cbc0944a64e2975",
      "0155f57d32ca45b39610fe136a4bd582",
      "12abad00fed24e09971133948486bc56",
      "c50d286360dd437ab75ffbe472048b1a",
      "22ee007df1a0416490e6820f96f62d69",
      "0e802f0837c7433e80f60ce73d89545f",
      "59d4f8ae414144b9a6c17d1bb9242966",
      "15abd623147a4e7aa3c9296865a448f2",
      "05a0f3b6188d439e80458f6ce1c3ac4e",
      "86a6b14479014e0397bf4eca15f26f49",
      "1ad024a22c3847ce93f936fcac74c056",
      "52acbcd9674547289bb6de0b5e1f4605",
      "93ef75bacca141669442d6111b47a5d6"
     ]
    },
    "id": "3489be5f",
    "outputId": "1d1b05db-c9a0-4ab7-a264-6f43077e2fb9"
   },
   "outputs": [],
   "source": [
    "# Загружаем модель и токенизатор\n",
    "model_name = \"Helsinki-NLP/opus-mt-ru-en\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3926162",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "059cdfaf3126445688f25ca566524aa8",
      "4f12d81a7b41408fb56f646fa34bf54c",
      "bc62bfa0e26c475aa80a08e65e27eec7",
      "e3b8ffa805fc4aa1ab927cd8dd01cf9e",
      "995ce46ae46a4d1e8c66c6b443735e4d",
      "d5c71704aee2415cb35a3b79b2f3ea52",
      "c4f1af3dd646466f8aef237a0f1c5eda",
      "48560420df014eaaad60af076bc74686",
      "a2db462bd22140f39f81dd3a9a0d5e00",
      "dd66bd597e77473e8a71c3f9e743d3ca",
      "20a07b12d1ba4be7aa207471d042a89f",
      "8cd7105358cf43d8847f36714b5fd27d",
      "9c222f17d08747348ef84219cd3112e9",
      "aad104d2246d4ea6a95efefb84951e98",
      "94cffd0f6a8f4a8bbd14be80cb2abe5f",
      "99440eaa53624ac4adac67a20b42b33c",
      "e1bee8d3e1b84df888d9a8f8b70cb2ea",
      "41ee8ab3eaef45188792173af288b734",
      "f828dc15e58e4af7a40b1e5cdadc8bab",
      "ee10b81ae6c040e4aa68123ffea4ace2",
      "7d9f7709d2544d55ab6224a657207351",
      "0732685933b24c9cac9d1b3f02928be8"
     ]
    },
    "id": "b3926162",
    "outputId": "86d8d194-c0de-4ca6-9316-c5a9579d525a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1135 [00:00<?, ? examples/s]c:\\Users\\mrpec\\OneDrive\\Рабочий стол\\ML_HSE\\Проект\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 1135/1135 [00:00<00:00, 1632.88 examples/s]\n",
      "Map: 100%|██████████| 127/127 [00:00<00:00, 2080.20 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Читаем датафрейм из файла\n",
    "data_frame = pd.read_csv(\"data/full_data_ver_2.csv\").drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Переводим датафрейм в датасет\n",
    "dataset = Dataset.from_pandas(data_frame)\n",
    "\n",
    "# Токенизируем\n",
    "def preprocess(example):\n",
    "    model_inputs = tokenizer(example[\"Russian\"], max_length=128, truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(example[\"English\"], max_length=128, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Делим на train/test\n",
    "split_dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "raw_train = split_dataset['train'] # Чистые колонки Russian, English на трейн\n",
    "raw_test = split_dataset['test']  # Чистые колонки Russian, English на тест\n",
    "\n",
    "# Токенизируем\n",
    "tokenized_train = raw_train.map(preprocess)\n",
    "tokenized_test = raw_test.map(preprocess)\n",
    "\n",
    "# Убираем в токенизированном датасете колонки со словами\n",
    "tokenized_train = tokenized_train.remove_columns([\"Russian\", \"English\"])\n",
    "tokenized_test = tokenized_test.remove_columns([\"Russian\", \"English\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bfae64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2bfae64",
    "outputId": "77f113f5-a3b8-468e-b8a1-96ada10b5487"
   },
   "outputs": [],
   "source": [
    "# Конфиг для LoRA\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "## В первой версии обучения я брал только \"q_proj\", \"k_proj\", думая, что это поможет модельке не переобучиться\n",
    "\n",
    "# Получаем модель для LoRA\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9fbc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1ce9fbc8",
    "outputId": "83d55405-82a5-408d-f74a-2cb8c529efe7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a28b1b5d66be>:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='710' max='710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [710/710 24:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.563200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.314400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.085300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.183600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.943300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.882800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.689300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.849900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.651100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.554900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.618600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.650200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.469200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.744300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.451200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.350700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.509300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.291600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.372400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.292500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.259800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.190100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.210200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.297200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.112100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.227400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.200200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.201600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.235500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.981200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.945700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.957400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.977600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.053600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.080400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.161700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.082200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.153600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.849500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.041400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.077200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.096000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.875300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.073800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.886300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.155100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.887700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.967700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.960600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=710, training_loss=1.3519981585757832, metrics={'train_runtime': 1475.4796, 'train_samples_per_second': 3.839, 'train_steps_per_second': 0.481, 'total_flos': 61218667560960.0, 'train_loss': 1.3519981585757832, 'epoch': 5.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Тренируем\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"lora-opus-ru-en\", # Этой директории нет, она осталась в коллабе\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=5e-4,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=1,\n",
    "    save_steps=100,\n",
    "    fp16=False,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    eval_dataset=tokenized_test\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Тут отображены эпохи для второй версии модели, обучал в колабе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CnMc6WyORs51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnMc6WyORs51",
    "outputId": "d60c34e9-096e-459a-9ac1-6bfe38dc930d"
   },
   "outputs": [],
   "source": [
    "# Сохраняем файлы модели\n",
    "model.save_pretrained(\"model_files\")\n",
    "tokenizer.save_pretrained(\"model_files\")\n",
    "\n",
    "# Названия для папок с файлами изменены на my_LoRA_ver1 и my_LoRA_ver2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TQVA7um0r5tF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQVA7um0r5tF",
    "outputId": "a642f9fd-d715-4bc9-8e2d-21dae2fc5a57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicken in honey glaze with grilled avocado and spinach\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")\n",
    "model = PeftModel.from_pretrained(base_model, \"my_LoRA_ver2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")\n",
    "\n",
    "translator = pipeline(\"translation\", model=model, tokenizer=tokenizer)  \n",
    "print(translator(\"Цыпленок в медовой глазури с авокадо гриль и шпинатом\")[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc16a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мне захотелось слить базовую модель и две мои LoRA в две версии моделей\n",
    "\n",
    "# Данные для моделей\n",
    "base_model_name = \"Helsinki-NLP/opus-mt-ru-en\"\n",
    "lora_ver1 = \"my_LoRA_ver1\"\n",
    "lora_ver2 = \"my_LoRA_ver2\"\n",
    "\n",
    "# Загружаем базовую модель и токенизатор\n",
    "base_model_1 = AutoModelForSeq2SeqLM.from_pretrained(base_model_name)\n",
    "base_model_2 = AutoModelForSeq2SeqLM.from_pretrained(base_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "# Загружаем LoRA поверх базовой модели\n",
    "model_ver1 = PeftModel.from_pretrained(base_model_1, lora_ver1)\n",
    "model_ver2 = PeftModel.from_pretrained(base_model_2, lora_ver2)\n",
    "\n",
    "# Объединяем веса и выгружаем LoRA\n",
    "merged_model_ver1 = model_ver1.merge_and_unload()\n",
    "merged_model_ver2 = model_ver2.merge_and_unload()\n",
    "\n",
    "# Сохраняем слитую модель и токенизатор\n",
    "\n",
    "merged_model_ver1.save_pretrained(\"my_model_ver1\")\n",
    "tokenizer.save_pretrained(\"my_model_ver1\")\n",
    "\n",
    "merged_model_ver2.save_pretrained(\"my_model_ver2\")\n",
    "tokenizer.save_pretrained(\"my_model_ver2\")\n",
    "\n",
    "# Все файлы неслитых моделей были перемещены в \"unfinished_models_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dE54YOTOZ4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97dE54YOTOZ4",
    "outputId": "da144e9c-3acd-4065-c43b-6a5c82a9a136"
   },
   "outputs": [],
   "source": [
    "# Оценка моделей\n",
    "def metrics(model, tokenizer, test_set):\n",
    "\n",
    "    # Делаю из датасета датафрейм\n",
    "    if type(test_set) != \"datasets.arrow_dataset.Dataset\":\n",
    "        test_set = test_set.to_pandas()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Грузим метрики\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "    chrf = evaluate.load(\"chrf\")\n",
    "\n",
    "    # Считаю предсказания\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for i, row in test_set.iterrows():\n",
    "        inputs = tokenizer(row[\"Russian\"], return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        outputs = model.generate(**inputs, max_length=128)\n",
    "        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        predictions.append(pred)\n",
    "        references.append([row[\"English\"]])  \n",
    "\n",
    "    # Считаю метрики\n",
    "    bleu_ = bleu.compute(predictions=predictions, references=references)['bleu']\n",
    "    chrf_ = chrf.compute(predictions=predictions, references=[r[0] for r in references])['score']\n",
    "    rouge_result = rouge.compute(predictions=predictions, references=[r[0] for r in references], rouge_types=[\"rougeL\"])\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"BLEU\": bleu_,\n",
    "        \"chrF\": chrf_,\n",
    "        \"ROUGE-L\": rouge_result[\"rougeL\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b68717",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(base_model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "metrics_model_base = metrics(base_model, tokenizer, raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b1f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ver1 = AutoModelForSeq2SeqLM.from_pretrained(\"my_model_ver1\")\n",
    "tokenizer_1 = AutoTokenizer.from_pretrained(\"my_model_ver1\")\n",
    "\n",
    "metrics_model_ver1 = metrics(model_ver1, tokenizer_1, raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da405f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ver2 = AutoModelForSeq2SeqLM.from_pretrained(\"my_model_ver2\")\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(\"my_model_ver2\")\n",
    "\n",
    "metrics_model_ver2 = metrics(model_ver2, tokenizer_2, raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7299ba45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLEU</th>\n",
       "      <th>chrF</th>\n",
       "      <th>ROUGE-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>OPUS-MT</th>\n",
       "      <td>0.195338</td>\n",
       "      <td>49.861544</td>\n",
       "      <td>0.502824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA ver.1</th>\n",
       "      <td>0.303787</td>\n",
       "      <td>58.646219</td>\n",
       "      <td>0.611332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA ver.2</th>\n",
       "      <td>0.508579</td>\n",
       "      <td>71.365081</td>\n",
       "      <td>0.722241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                BLEU       chrF   ROUGE-L\n",
       "OPUS-MT     0.195338  49.861544  0.502824\n",
       "LoRA ver.1  0.303787  58.646219  0.611332\n",
       "LoRA ver.2  0.508579  71.365081  0.722241"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.concat([\n",
    "    pd.DataFrame([metrics_model_base], index=[\"OPUS-MT\"]),\n",
    "    pd.DataFrame([metrics_model_ver1], index=[\"LoRA ver.1\"]),\n",
    "    pd.DataFrame([metrics_model_ver2], index=[\"LoRA ver.2\"])\n",
    "], axis=0)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b11700",
   "metadata": {},
   "source": [
    "#### Как видно из метрик - LoRA сработал, неудивительно что модель второй версии показывает себя лучше, там дообучался полный attention и данных в целом было больше. \n",
    "\n",
    "#### Дальшет я попробую разобраться с gradio -> **UI_model**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
